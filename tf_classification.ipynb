{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOt/LALuPYJ3l3BxMNqe+Xw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Moussaoui-Ghiles/tensorflow-2.0/blob/main/tf_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sklearn\n",
        "\n",
        "import pandas as pd \n",
        "import tensorflow as tf \n",
        "\n",
        "import numpy as np \n"
      ],
      "metadata": {
        "id": "EwbGqOiuTfwa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c660eeaf-1266-4df3-8b38-2e0d0fb333e7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI3zi2ZhQ3WB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1975933f-5723-4745-a98e-2c8e434c9bb6"
      },
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
        "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
        "# Lets define some constants to help us later on\n",
        "\n",
        "\n",
        "train_path = tf.keras.utils.get_file(\n",
        "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
        "test_path = tf.keras.utils.get_file(\n",
        "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
        "\n",
        "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "# Here we use keras (a module inside of TensorFlow) to grab our datasets and read them into a pandas dataframe\n",
        "\n",
        "\n",
        "\n",
        "train_y = train.pop(\"Species\")\n",
        "test_y = test.pop(\"Species\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def input_fn(features, labels, training = True , batch_size = 256):\n",
        "\n",
        "  # convert the inputs to a Dataset\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "\n",
        "  # shuffle and repeat if you are in training mode \n",
        "\n",
        "  if training:\n",
        "    dataset = dataset.shuffle(1000).repeat()\n",
        "  return dataset.batch(batch_size)\n",
        "\n",
        "\n",
        "\n",
        "# feature columns \n",
        "#Feature columns describe how to use the input \n",
        "my_feature_columns= []\n",
        "for key in train.keys():\n",
        "  my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
        "\n",
        "\n",
        "# Build a DNN with 2 hidden layers with 30 and 10 hiden nodes each \n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "    feature_columns = my_feature_columns,\n",
        "    hidden_units = [30, 10],\n",
        "    # the model must choose between 3 classes \n",
        "    n_classes = 3 \n",
        ")\n",
        "\n",
        "\n",
        "#TRAINING \n",
        "\n",
        "classifier.train(\n",
        "    input_fn = lambda: input_fn(train, train_y, training = True), \n",
        "    steps = 5000\n",
        ")# we include a lambda to avoid creating an inner function previously\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CH4lBNuRTpLi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a3526a2-0687-492e-9cee-52e7f63158ca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp723sbzxb\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:397: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adagrad.py:87: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 2136 vs previous value: 2136. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7f88a40df6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation \n",
        "\n",
        "\n",
        "eval_result = classifier.evaluate(\n",
        "    input_fn = lambda: input_fn(test, test_y, training = False)\n",
        ")\n",
        "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhMp6ZI-rSZU",
        "outputId": "1b3c1001-d99f-40fd-89c2-d48cab9d64fd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set accuracy: 0.867\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction \n",
        "\n",
        "\n",
        "def input_fn(features, batch_size=256):\n",
        "    # Convert the inputs to a Dataset without labels.\n",
        "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
        "\n",
        "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
        "predict = {}\n",
        "\n",
        "print(\"Please type numeric values as prompted.\")\n",
        "for feature in features:\n",
        "  valid = True\n",
        "  while valid: \n",
        "    val = input(feature + \": \")\n",
        "    if not val.isdigit(): valid = False\n",
        "\n",
        "  predict[feature] = [float(val)]\n",
        "\n",
        "predictions = classifier.predict(input_fn=lambda: input_fn(predict))\n",
        "for pred_dict in predictions:\n",
        "    class_id = pred_dict['class_ids'][0]\n",
        "    probability = pred_dict['probabilities'][class_id]\n",
        "\n",
        "    print('Prediction is \"{}\" ({:.1f}%)'.format(\n",
        "        SPECIES[class_id], 100 * probability))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fDMkZJGrwbl",
        "outputId": "864d1e59-4ab0-44ed-ce91-a0722d653a1b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please type numeric values as prompted.\n",
            "SepalLength: 3.34\n",
            "SepalWidth: 5.2\n",
            "PetalLength: 23\n",
            "PetalLength: 5.3\n",
            "PetalWidth: 34.4\n",
            "Prediction is \"Virginica\" (100.0%)\n"
          ]
        }
      ]
    }
  ]
}